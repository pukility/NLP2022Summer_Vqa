{"metadata": {"kernelspec": {"name": "mindspore-python3.7-aarch64", "display_name": "MindSpore-python3.7-aarch64", "language": "python"}, "language_info": {"name": "python", "version": "3.7.6", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}, "vscode": {"interpreter": {"hash": "273a006c09da788b9f4a1e15f42acee9457fe9899d6a5890d2a7cc7128ac0f24"}}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "code", "source": "import moxing as mox\nfrom mindspore import context\ncontext.set_context(mode=context.GRAPH_MODE, device_target=\"Ascend\")", "metadata": {"trusted": true}, "execution_count": 1, "outputs": [{"name": "stderr", "text": "INFO:root:Using MoXing-v2.0.0.rc2.4b57a67b-4b57a67b\nINFO:root:Using OBS-Python-SDK-3.20.9.1\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "! pip install mindvision", "metadata": {"trusted": true}, "execution_count": 2, "outputs": [{"name": "stdout", "text": "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\nCollecting mindvision\n  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/da/35/8e45c5b695706e3f3328014ab4ec8baa4290b8339390570284127069ef9a/mindvision-0.1.0-py3-none-any.whl (194 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 194 kB 4.8 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages (from mindvision) (7.0.0)\nCollecting tqdm\n  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/a6/73/7780b2c0868bdce1f13ce27b09b239f0eefc975a5c7ebc82a7613b2a2f05/tqdm-4.63.1-py2.py3-none-any.whl (76 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 76 kB 10.0 MB/s eta 0:00:01\n\u001b[?25hCollecting pytest>=4.3.1\n  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/fb/d0/bae533985f2338c5d02184b4a7083b819f6b3fc101da792e0d96e6e5299d/pytest-7.1.2-py3-none-any.whl (297 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 297 kB 18.9 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: easydict>=1.9 in /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages (from mindvision) (1.9)\nRequirement already satisfied: numpy>=1.17.0 in /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages (from mindvision) (1.17.5)\nCollecting ml-collections\n  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/aa/ea/853aa32dfa1006d3eb43384712f35b8f2d6f0a757b8c779d40c29e3e8515/ml_collections-0.1.1.tar.gz (77 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 77 kB 4.7 MB/s eta 0:00:01\n\u001b[?25hCollecting opencv-contrib-python-headless\n  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/c9/14/8246c7a25f18e1de13a10d28f90cc63bc6fb8d66cb95b7729bd9f7a4cf31/opencv_contrib_python_headless-4.6.0.66-cp36-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (33.0 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33.0 MB 13.4 MB/s eta 0:00:01\n\u001b[?25hCollecting opencv-python-headless\n  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/23/1f/8065928a1be8f47ca2f941bfbc35df0a294a721ed3613b51c78bf7b0867c/opencv_python_headless-4.6.0.66-cp36-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (27.2 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 27.2 MB 24.5 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: scikit-learn>=0.23.1 in /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages (from mindvision) (0.24.0)\nRequirement already satisfied: scipy>=1.5.2 in /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages (from mindvision) (1.5.4)\nCollecting matplotlib>=3.2.1\n  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/83/56/8080af16635d10a6876bab52ee9ab0c25b410bb1080aba12c12bb4be68eb/matplotlib-3.5.2-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (11.6 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 11.6 MB 5.5 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: setuptools>=40.8.0 in /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages (from mindvision) (52.0.0.post20210302)\nRequirement already satisfied: wheel>=0.32.0 in /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages (from mindvision) (0.37.0)\nRequirement already satisfied: packaging>=20.0 in /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages (from matplotlib>=3.2.1->mindvision) (21.0)\nRequirement already satisfied: python-dateutil>=2.7 in /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages (from matplotlib>=3.2.1->mindvision) (2.8.2)\nRequirement already satisfied: cycler>=0.10 in /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages (from matplotlib>=3.2.1->mindvision) (0.10.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages (from matplotlib>=3.2.1->mindvision) (1.1.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages (from matplotlib>=3.2.1->mindvision) (2.4.7)\nCollecting fonttools>=4.22.0\n  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/2f/85/2f6e42fb4b537b9998835410578fb1973175b81691e9a82ab6668cf64b0b/fonttools-4.33.3-py3-none-any.whl (930 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 930 kB 17.1 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: six in /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages (from cycler>=0.10->matplotlib>=3.2.1->mindvision) (1.16.0)\nCollecting py>=1.8.2\n  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/67/32/6fe01cfc3d1a27c92fdbcdfc3f67856da8cbadf0dd9f2e18055202b2dc62/py-1.10.0-py2.py3-none-any.whl (97 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 97 kB 55.9 MB/s eta 0:00:01\n\u001b[?25hCollecting pluggy<2.0,>=0.12\n  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/9e/01/f38e2ff29715251cf25532b9082a1589ab7e4f571ced434f98d0139336dc/pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\nRequirement already satisfied: attrs>=19.2.0 in /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages (from pytest>=4.3.1->mindvision) (19.3.0)\nCollecting tomli>=1.0.0\n  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/97/75/10a9ebee3fd790d20926a90a2547f0bf78f371b2f13aa822c759680ca7b9/tomli-2.0.1-py3-none-any.whl (12 kB)\nCollecting importlib-metadata>=0.12\n  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/d2/a2/8c239dc898138f208dd14b441b196e7b3032b94d3137d9d8453e186967fc/importlib_metadata-4.12.0-py3-none-any.whl (21 kB)\nCollecting iniconfig\n  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/9b/dd/b3c12c6d707058fa947864b67f0c4e0c39ef8610988d7baea9578f3c48f3/iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\nCollecting zipp>=0.5\n  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/52/c5/df7953fe6065185af5956265e3b16f13c2826c2b1ba23d43154f3af453bc/zipp-3.7.0-py3-none-any.whl (5.3 kB)\nRequirement already satisfied: typing-extensions>=3.6.4 in /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest>=4.3.1->mindvision) (3.10.0.0)\nRequirement already satisfied: joblib>=0.11 in /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages (from scikit-learn>=0.23.1->mindvision) (1.0.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages (from scikit-learn>=0.23.1->mindvision) (2.2.0)\nCollecting absl-py\n  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/11/8d/5fce604f03c8d30aa0d45451e67efe30d23e65eec7bbef9b9d341b86c0ef/absl_py-1.1.0-py3-none-any.whl (123 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 123 kB 57.5 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: PyYAML in /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages (from ml-collections->mindvision) (5.3.1)\nCollecting contextlib2\n  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/76/56/6d6872f79d14c0cb02f1646cbb4592eef935857c0951a105874b7b62a0c3/contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\nCollecting numpy>=1.17.0\n  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/b7/0d/86662f93102e42545cdf031da4fddf0ace9030ec67478932a628afc5973b/numpy-1.21.6-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (13.0 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 13.0 MB 13.9 MB/s eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: ml-collections\n  Building wheel for ml-collections (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ml-collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94497 sha256=3facd73c5c0f0dbee801fe3d4b4bbd1adcc872ade9545935bc7f2a64c471aa69\n  Stored in directory: /home/ma-user/.cache/pip/wheels/99/c3/28/3b58c360d4ed678c4f045bc99e3ac99b1e0f7ca45f1da41437\nSuccessfully built ml-collections\nInstalling collected packages: zipp, numpy, importlib-metadata, tomli, py, pluggy, iniconfig, fonttools, contextlib2, absl-py, tqdm, pytest, opencv-python-headless, opencv-contrib-python-headless, ml-collections, matplotlib, mindvision\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.17.5\n    Uninstalling numpy-1.17.5:\n      Successfully uninstalled numpy-1.17.5\n  Attempting uninstall: matplotlib\n    Found existing installation: matplotlib 3.1.2\n    Uninstalling matplotlib-3.1.2:\n      Successfully uninstalled matplotlib-3.1.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nschedule-search 0.0.1 requires tensorflow>=1.10.0, which is not installed.\u001b[0m\nSuccessfully installed absl-py-1.1.0 contextlib2-21.6.0 fonttools-4.33.3 importlib-metadata-4.12.0 iniconfig-1.1.1 matplotlib-3.5.2 mindvision-0.1.0 ml-collections-0.1.1 numpy-1.21.6 opencv-contrib-python-headless-4.6.0.66 opencv-python-headless-4.6.0.66 pluggy-1.0.0 py-1.10.0 pytest-7.1.2 tomli-2.0.1 tqdm-4.63.1 zipp-3.7.0\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "import argparse\nimport os.path as osp\n\nfrom mindspore import context\n\nfrom NLP2022Summer_Vqa.engine import Trainer\nfrom NLP2022Summer_Vqa.model import vqa_model\nfrom NLP2022Summer_Vqa.utils import Tokenizer\nfrom NLP2022Summer_Vqa.data import build_dataset\nfrom NLP2022Summer_Vqa.config import get_default_cfg\n\ndef reset_cfg(cfg, args):\n    if args.question_dir:\n        cfg[\"que_path\"] = args.question_dir\n\n    if args.image_path:\n        cfg[\"img_path\"] = args.image_path\n\n    if args.answer_dir:\n        cfg[\"ans_path\"] = args.answer_dir\n\n    if args.glove_dir:\n        cfg[\"glove_path\"] = args.glove_dir\n\n    if args.embd_dir:\n        cfg[\"embd_path\"] = args.embd_dir\n\n    if args.output_dir:\n        cfg.OUTPUT_DIR = args.output_dir\n\n\ndef setup_cfg(args):\n    cfg = get_default_cfg()\n\n    # 1. From the dataset config file\n    if args.dataset_config_file:\n        #cfg.merge_from_file(args.dataset_config_file)\n        pass\n    # 2. From the method config file\n    if args.config_file:\n        #cfg.merge_from_file(args.config_file)\n        pass\n    # 3. From input arguments\n    reset_cfg(cfg, args)\n\n    return cfg\n\n\ndef main():\n    cfg = get_default_cfg()\n\n    data_parser = Tokenizer(cfg)\n    data_parser.parse()\n\n\n    model = vqa_model(cfg)\n    train_loader = build_dataset(cfg, data_parser, \"train\")\n    val_loader = build_dataset(cfg, data_parser, \"val\")\n    test_loader = build_dataset(cfg, data_parser, \"test\")\n    trainer = Trainer(model, cfg, train_loader, val_loader, test_loader)\n    return trainer\n", "metadata": {"trusted": true}, "execution_count": 3, "outputs": []}, {"cell_type": "code", "source": "trainer = main()", "metadata": {"trusted": true}, "execution_count": 4, "outputs": [{"name": "stdout", "text": "Embedding weight already exists, skip parsing weight file\n=======================Start parse train=======================\nThe vocab size of train set is 9448\n=======================Start parse val=======================\nThe vocab size of val set is 6836\n=======================Start parse test=======================\nThe vocab size of test set is 6819\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "trainer.train()", "metadata": {"trusted": true}, "execution_count": 5, "outputs": [{"name": "stderr", "text": "Train epoch  0: 100% 86/86 [02:08<00:00,  1.49s/it]\nValidate epoch  0: 100% 41/41 [00:27<00:00,  1.47it/s]\n", "output_type": "stream"}, {"name": "stdout", "text": "Epoch  0:\nLoss: 6.3532, Accuracy: 0.3471\n", "output_type": "stream"}, {"name": "stderr", "text": "Train epoch  1: 100% 86/86 [01:45<00:00,  1.22s/it]\nValidate epoch  1: 100% 41/41 [00:26<00:00,  1.57it/s]\n", "output_type": "stream"}, {"name": "stdout", "text": "Epoch  1:\nLoss: 6.3463, Accuracy: 0.3468\n", "output_type": "stream"}, {"name": "stderr", "text": "Train epoch  2: 100% 86/86 [01:39<00:00,  1.16s/it]\nValidate epoch  2: 100% 41/41 [00:26<00:00,  1.56it/s]\n", "output_type": "stream"}, {"name": "stdout", "text": "Epoch  2:\nLoss: 6.3376, Accuracy: 0.3465\n", "output_type": "stream"}, {"name": "stderr", "text": "Train epoch  3: 100% 86/86 [01:39<00:00,  1.15s/it]\nValidate epoch  3: 100% 41/41 [00:25<00:00,  1.59it/s]\n", "output_type": "stream"}, {"name": "stdout", "text": "Epoch  3:\nLoss: 6.1776, Accuracy: 0.4485\n", "output_type": "stream"}, {"name": "stderr", "text": "Train epoch  4: 100% 86/86 [01:49<00:00,  1.27s/it]\nValidate epoch  4: 100% 41/41 [00:24<00:00,  1.64it/s]\n", "output_type": "stream"}, {"name": "stdout", "text": "Epoch  4:\nLoss: 5.7734, Accuracy: 0.5087\n", "output_type": "stream"}, {"name": "stderr", "text": "Train epoch  5: 100% 86/86 [01:40<00:00,  1.17s/it]\nValidate epoch  5: 100% 41/41 [00:24<00:00,  1.64it/s]\n", "output_type": "stream"}, {"name": "stdout", "text": "Epoch  5:\nLoss: 6.0833, Accuracy: 0.4648\n", "output_type": "stream"}, {"name": "stderr", "text": "Train epoch  6: 100% 86/86 [01:40<00:00,  1.17s/it]\nValidate epoch  6: 100% 41/41 [00:24<00:00,  1.65it/s]\n", "output_type": "stream"}, {"name": "stdout", "text": "Epoch  6:\nLoss: 5.9328, Accuracy: 0.4801\n", "output_type": "stream"}, {"name": "stderr", "text": "Train epoch  7: 100% 86/86 [01:48<00:00,  1.26s/it]\nValidate epoch  7: 100% 41/41 [00:23<00:00,  1.74it/s]\n", "output_type": "stream"}, {"name": "stdout", "text": "Epoch  7:\nLoss: 5.8538, Accuracy: 0.4837\n", "output_type": "stream"}, {"name": "stderr", "text": "Train epoch  8: 100% 86/86 [01:41<00:00,  1.18s/it]\nValidate epoch  8: 100% 41/41 [00:25<00:00,  1.60it/s]\n", "output_type": "stream"}, {"name": "stdout", "text": "Epoch  8:\nLoss: 5.8027, Accuracy: 0.4839\n", "output_type": "stream"}, {"name": "stderr", "text": "Train epoch  9: 100% 86/86 [01:46<00:00,  1.24s/it]\nValidate epoch  9: 100% 41/41 [00:24<00:00,  1.64it/s]\n", "output_type": "stream"}, {"name": "stdout", "text": "Epoch  9:\nLoss: 5.7631, Accuracy: 0.4824\n", "output_type": "stream"}, {"name": "stderr", "text": "Train epoch 10: 100% 86/86 [01:39<00:00,  1.16s/it]\nValidate epoch 10: 100% 41/41 [00:23<00:00,  1.77it/s]\n", "output_type": "stream"}, {"name": "stdout", "text": "Epoch 10:\nLoss: 5.7445, Accuracy: 0.4809\n", "output_type": "stream"}, {"name": "stderr", "text": "Train epoch 11: 100% 86/86 [01:41<00:00,  1.18s/it]\nValidate epoch 11: 100% 41/41 [00:24<00:00,  1.68it/s]\n", "output_type": "stream"}, {"name": "stdout", "text": "Epoch 11:\nLoss: 5.7544, Accuracy: 0.4781\n", "output_type": "stream"}, {"name": "stderr", "text": "Train epoch 12: 100% 86/86 [01:41<00:00,  1.18s/it]\nValidate epoch 12: 100% 41/41 [00:25<00:00,  1.63it/s]\n", "output_type": "stream"}, {"name": "stdout", "text": "Epoch 12:\nLoss: 5.7334, Accuracy: 0.4748\n", "output_type": "stream"}, {"name": "stderr", "text": "Train epoch 13: 100% 86/86 [01:44<00:00,  1.21s/it]\nValidate epoch 13: 100% 41/41 [00:24<00:00,  1.65it/s]\n", "output_type": "stream"}, {"name": "stdout", "text": "Epoch 13:\nLoss: 5.6743, Accuracy: 0.4720\n", "output_type": "stream"}, {"name": "stderr", "text": "Train epoch 14: 100% 86/86 [01:40<00:00,  1.17s/it]\nValidate epoch 14: 100% 41/41 [00:25<00:00,  1.62it/s]\n", "output_type": "stream"}, {"name": "stdout", "text": "Epoch 14:\nLoss: 5.5565, Accuracy: 0.4832\n", "output_type": "stream"}, {"name": "stderr", "text": "Train epoch 15: 100% 86/86 [01:40<00:00,  1.17s/it]\nValidate epoch 15: 100% 41/41 [00:26<00:00,  1.55it/s]\n", "output_type": "stream"}, {"name": "stdout", "text": "Epoch 15:\nLoss: 5.5145, Accuracy: 0.4906\n", "output_type": "stream"}, {"name": "stderr", "text": "Train epoch 16: 100% 86/86 [01:40<00:00,  1.16s/it]\nValidate epoch 16: 100% 41/41 [00:25<00:00,  1.61it/s]\n", "output_type": "stream"}, {"name": "stdout", "text": "Epoch 16:\nLoss: 5.5357, Accuracy: 0.4836\n", "output_type": "stream"}, {"name": "stderr", "text": "Train epoch 17: 100% 86/86 [01:45<00:00,  1.23s/it]\nValidate epoch 17: 100% 41/41 [00:25<00:00,  1.60it/s]\n", "output_type": "stream"}, {"name": "stdout", "text": "Epoch 17:\nLoss: 5.4628, Accuracy: 0.4968\n", "output_type": "stream"}, {"name": "stderr", "text": "Train epoch 18: 100% 86/86 [01:41<00:00,  1.18s/it]\nValidate epoch 18: 100% 41/41 [00:26<00:00,  1.55it/s]\n", "output_type": "stream"}, {"name": "stdout", "text": "Epoch 18:\nLoss: 5.4502, Accuracy: 0.4934\n", "output_type": "stream"}, {"name": "stderr", "text": "Train epoch 19: 100% 86/86 [01:37<00:00,  1.13s/it]\nValidate epoch 19: 100% 41/41 [00:25<00:00,  1.59it/s]\n", "output_type": "stream"}, {"name": "stdout", "text": "Epoch 19:\nLoss: 5.3644, Accuracy: 0.5010\n", "output_type": "stream"}, {"name": "stderr", "text": "Train epoch 20: 100% 86/86 [01:44<00:00,  1.22s/it]\nValidate epoch 20: 100% 41/41 [00:25<00:00,  1.64it/s]\n", "output_type": "stream"}, {"name": "stdout", "text": "Epoch 20:\nLoss: 5.3658, Accuracy: 0.4973\n", "output_type": "stream"}, {"name": "stderr", "text": "Train epoch 21: 100% 86/86 [01:38<00:00,  1.15s/it]\nValidate epoch 21: 100% 41/41 [00:28<00:00,  1.44it/s]\n", "output_type": "stream"}, {"name": "stdout", "text": "Epoch 21:\nLoss: 5.3094, Accuracy: 0.4987\n", "output_type": "stream"}, {"name": "stderr", "text": "Train epoch 22: 100% 86/86 [01:40<00:00,  1.16s/it]\nValidate epoch 22: 100% 41/41 [00:23<00:00,  1.73it/s]\n", "output_type": "stream"}, {"name": "stdout", "text": "Epoch 22:\nLoss: 5.3757, Accuracy: 0.4887\n", "output_type": "stream"}, {"name": "stderr", "text": "Train epoch 23: 100% 86/86 [01:38<00:00,  1.14s/it]\nValidate epoch 23: 100% 41/41 [00:23<00:00,  1.73it/s]\n", "output_type": "stream"}, {"name": "stdout", "text": "Epoch 23:\nLoss: 5.3382, Accuracy: 0.4861\n", "output_type": "stream"}, {"name": "stderr", "text": "Train epoch 24: 100% 86/86 [01:42<00:00,  1.19s/it]\nValidate epoch 24: 100% 41/41 [00:24<00:00,  1.65it/s]\n", "output_type": "stream"}, {"name": "stdout", "text": "Epoch 24:\nLoss: 5.3320, Accuracy: 0.4844\n", "output_type": "stream"}, {"name": "stderr", "text": "Train epoch 25: 100% 86/86 [01:37<00:00,  1.13s/it]\nValidate epoch 25: 100% 41/41 [00:25<00:00,  1.63it/s]\n", "output_type": "stream"}, {"name": "stdout", "text": "Epoch 25:\nLoss: 5.2611, Accuracy: 0.4915\n", "output_type": "stream"}, {"name": "stderr", "text": "Train epoch 26: 100% 86/86 [01:38<00:00,  1.15s/it]\nValidate epoch 26: 100% 41/41 [00:24<00:00,  1.71it/s]\n", "output_type": "stream"}, {"name": "stdout", "text": "Epoch 26:\nLoss: 5.2606, Accuracy: 0.4909\n", "output_type": "stream"}, {"name": "stderr", "text": "Train epoch 27: 100% 86/86 [01:41<00:00,  1.18s/it]\nValidate epoch 27: 100% 41/41 [00:25<00:00,  1.59it/s]\n", "output_type": "stream"}, {"name": "stdout", "text": "Epoch 27:\nLoss: 5.2344, Accuracy: 0.4889\n", "output_type": "stream"}, {"name": "stderr", "text": "Train epoch 28: 100% 86/86 [01:45<00:00,  1.23s/it]\nValidate epoch 28: 100% 41/41 [00:25<00:00,  1.64it/s]\n", "output_type": "stream"}, {"name": "stdout", "text": "Epoch 28:\nLoss: 5.3087, Accuracy: 0.4893\n", "output_type": "stream"}, {"name": "stderr", "text": "Train epoch 29: 100% 86/86 [01:39<00:00,  1.16s/it]\nValidate epoch 29: 100% 41/41 [00:23<00:00,  1.75it/s]", "output_type": "stream"}, {"name": "stdout", "text": "Epoch 29:\nLoss: 5.1926, Accuracy: 0.4956\n", "output_type": "stream"}, {"name": "stderr", "text": "\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "trainer.test()", "metadata": {"trusted": true}, "execution_count": 6, "outputs": [{"name": "stderr", "text": "Test: 100% 41/41 [00:27<00:00,  1.52it/s]", "output_type": "stream"}, {"name": "stdout", "text": "Test results:\nLoss: 5.2608, Accuracy: 0.4906\n", "output_type": "stream"}, {"name": "stderr", "text": "\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "mox.file.copy_parallel(src_url=\"s3://hkp/nlp/NLP2022Summer_Vqa/\", dst_url=\"./NLP2022Summer_Vqa\")", "metadata": {"trusted": true}, "execution_count": 4, "outputs": []}, {"cell_type": "code", "source": "mox.file.copy_parallel(src_url=\"s3://hkp/nlp/NLP2022Summer_Vqa/engine/trainer_mindspore.py\", dst_url=\"./NLP2022Summer_Vqa/engine/trainer_mindspore.py\")\nmox.file.copy_parallel(src_url=\"s3://hkp/nlp/NLP2022Summer_Vqa/utils/tokenizer.py\", dst_url=\"./NLP2022Summer_Vqa/utils/tokenizer.py\")\nmox.file.copy_parallel(src_url=\"s3://hkp/nlp/NLP2022Summer_Vqa/utils/vqaevaluate.py\", dst_url=\"./NLP2022Summer_Vqa/utils/vqaevaluate.py\")\nmox.file.copy_parallel(src_url=\"s3://hkp/nlp/NLP2022Summer_Vqa/data/dataset.py\", dst_url=\"./NLP2022Summer_Vqa/data/dataset.py\")\nmox.file.copy_parallel(src_url=\"s3://hkp/nlp/NLP2022Summer_Vqa/model/model_mindspore.py\", dst_url=\"./NLP2022Summer_Vqa/model/model_mindspore.py\")\nmox.file.copy_parallel(src_url=\"s3://hkp/nlp/NLP2022Summer_Vqa/model/question_embedding.py\", dst_url=\"./NLP2022Summer_Vqa/model/question_embedding.py\")\nmox.file.copy_parallel(src_url=\"s3://hkp/nlp/NLP2022Summer_Vqa/config/config_mindspore.py\", dst_url=\"./NLP2022Summer_Vqa/config/config_mindspore.py\")", "metadata": {"trusted": true}, "execution_count": 2, "outputs": []}, {"cell_type": "code", "source": "mox.file.copy_parallel(src_url=\"s3://hkp/nlp/NLP2022Summer_Vqa/utils/__init__.py\", dst_url=\"./NLP2022Summer_Vqa/utils/__init__.py\")\nmox.file.copy_parallel(src_url=\"s3://hkp/nlp/NLP2022Summer_Vqa/data/__init__.py\", dst_url=\"./NLP2022Summer_Vqa/data/__init__.py\")\nmox.file.copy_parallel(src_url=\"s3://hkp/nlp/NLP2022Summer_Vqa/config/__init__.py\", dst_url=\"./NLP2022Summer_Vqa/config/__init__.py\")", "metadata": {}, "execution_count": 5, "outputs": []}, {"cell_type": "code", "source": "", "metadata": {}, "execution_count": null, "outputs": []}]}